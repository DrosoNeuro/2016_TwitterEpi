c <- matrix(c(20,80,30,70,35,65),2,3)
b <- c
p1 <- b[1,1]/(b[1,1]+b[2,1])
p2 <- b[1,2]/(b[1,2]+b[2,2])
p3 <- b[1,3]/(b[1,3]+b[2,3])
p4 <- (b[1,1]+b[1,2])/(b[1,2]+b[1,1]+b[2,2]+b[2,1])
p <- (b[1,1]+b[1,2]+b[1,3])/sum(b)
l1 <-b[1,1]*log(p1)+b[2,1]*log(1-p1) + b[1,2]*log(p2)+b[2,2]*log(1-p2) + b[1,3]*log(p3)+b[2,3]*log(1-p3)
l2 <-(b[1,1]+b[1,2])*log(p4)+(b[2,1]+b[2,2])*log(1-p4) + b[1,3]*log(p3)+b[2,3]*log(1-p3)
l3 <- sum(b[1,])*log(p) + sum(b[2,])*log(1-p)
t1 <- -2*(l2-l1)
t1
t2 <- -2*(l3-l2)
t2
t3 <- -2*(l3-l1)
t3
crit_val1df <- 3.84
crit_val2df <- 5.99
a <- matrix(c(15,200,50,450,135,150),2,3)
b  <- matrix(c(30,185,110,390,70,225),2,3)
c <- matrix(c(19,81,30,70,35,65),2,3)
b <- c
p1 <- b[1,1]/(b[1,1]+b[2,1])
p2 <- b[1,2]/(b[1,2]+b[2,2])
p3 <- b[1,3]/(b[1,3]+b[2,3])
p4 <- (b[1,1]+b[1,2])/(b[1,2]+b[1,1]+b[2,2]+b[2,1])
p <- (b[1,1]+b[1,2]+b[1,3])/sum(b)
l1 <-b[1,1]*log(p1)+b[2,1]*log(1-p1) + b[1,2]*log(p2)+b[2,2]*log(1-p2) + b[1,3]*log(p3)+b[2,3]*log(1-p3)
l2 <-(b[1,1]+b[1,2])*log(p4)+(b[2,1]+b[2,2])*log(1-p4) + b[1,3]*log(p3)+b[2,3]*log(1-p3)
l3 <- sum(b[1,])*log(p) + sum(b[2,])*log(1-p)
t1 <- -2*(l2-l1)
t1
t2 <- -2*(l3-l2)
t2
t3 <- -2*(l3-l1)
t3
crit_val1df <- 3.84
crit_val2df <- 5.99
pmm <- matrix(c(10,35,20,8,20,30,22,8.5,2.3,9,1.5,3),4,4)
pt <- matrix(c(5,6,10,8,19,22,10,7.5,15,5,18,19,2.3,2,5,3,4,7,0.5,1.25,3.5,2,5,8.5),4,4)
pmm
pt
pmm <- dataframe(matrix(c(10,35,20,8,20,30,22,8.5,2.3,9,1.5,3),4,4))
pt <- dataframe(matrix(c(5,6,10,8,19,22,10,7.5,15,5,18,19,2.3,2,5,3,4,7,0.5,1.25,3.5,2,5,8.5),4,4))
pmm <- data.frame(matrix(c(10,35,20,8,20,30,22,8.5,2.3,9,1.5,3),4,4))
pt <- data.frame(matrix(c(5,6,10,8,19,22,10,7.5,15,5,18,19,2.3,2,5,3,4,7,0.5,1.25,3.5,2,5,8.5),4,4))
pmm$time <- pmm[,1]-pmm[,2]
pmm$cost <- pmm[,3]-pmm[,4]
pt$time <- pt[,1]-pt[,2]
pt$time <- pt[,3]-pt[,4]
pmm
ptt
pt
pt$time <- pt[,1]-pt[,2]
pt$cost <- pt[,3]-pt[,4]
pt
pt
pmm <- data.frame(matrix(c(10,35,20,8,20,30,22,8.5,2.3,9,1.5,3),4,4))
pt <- data.frame(matrix(c(5,6,10,8,19,22,10,7.5,15,5,18,19,2.3,2,5,3,4,7,0.5,1.25,3.5,2,5,8.5),6,4))
pmm$time <- pmm[,1]-pmm[,2]
pmm$cost <- pmm[,3]-pmm[,4]
pt$time <- pt[,1]-pt[,2]
pt$cost <- pt[,3]-pt[,4]
pt
plot(pt$time,pt$cost)
plot(pt$time,pt$cost,"ro")
help(plot)
plot(pt$time,pt$cost,xlim=c(-15,15),ylim=c(-6,6),"p")
plot(pt$time,pt$cost,xlim=c(-15,15),ylim=c(-6,6),"p",col="r")
plot(pt$time,pt$cost,xlim=c(-15,15),ylim=c(-6,6),"p",color="r")
plot(pt$time,pt$cost,xlim=c(-15,15),ylim=c(-6,6),pch=0)
warnings()
plot(pt$time,pt$cost,xlim=c(-15,15),ylim=c(-6,6),pch=0,col=1)
plot(pt$time,pt$cost,xlim=c(-15,15),ylim=c(-6,6),pch=0,col=0)
plot(pt$time,pt$cost,xlim=c(-15,15),ylim=c(-6,6),pch=0,col=2)
points(pmm$time,pmm$cost,pch=2,col=3)
pmm$time
pmm$cost
pmm
pmm <- data.frame(matrix(c(10,35,20,8,20,30,22,8.5,2.3,9,1.5,3),4,4))
pmm
pmm <- data.frame(matrix(c(10,35,20,8,20,30,22,8.5,2.3,9,1.5,3,1,12,2,9),4,4))
pt <- data.frame(matrix(c(5,6,10,8,19,22,10,7.5,15,5,18,19,2.3,2,5,3,4,7,0.5,1.25,3.5,2,5,8.5),6,4))
pmm$time <- pmm[,1]-pmm[,2]
pmm$cost <- pmm[,3]-pmm[,4]
pt$time <- pt[,1]-pt[,2]
pt$cost <- pt[,3]-pt[,4]
plot(pt$time,pt$cost,xlim=c(-15,15),ylim=c(-6,6),pch=0,col=2)
points(pmm$time,pmm$cost,pch=2,col=3)
trend <- function(x, beta)
{
y <- beta*x
}
help(lines)
x <- seq(-15,15)
x
trend <- function(x, beta)
{
y <- beta*x
}
beta <- -0.2630
x <- seq(-15,15)
y <- trend(x,beta)
y
x[-1]
x[1]
tail(x,1)
lines(c(x[1],y[1]),c(tail(x,1),tail(y,1)))
tail(y,1)
tail(x,1)
lines(c(x[1],tail(x,1)),c(head(y,1),tail(y,1)))
pmm <- data.frame(matrix(c(10,35,20,8,20,30,22,8.5,2.3,9,1.5,3,1,12,2,9),4,4))
pt <- data.frame(matrix(c(5,6,10,8,19,22,10,7.5,15,5,18,19,2.3,2,5,3,4,7,0.5,1.25,3.5,2,5,8.5),6,4))
pmm$time <- pmm[,1]-pmm[,2]
pmm$cost <- pmm[,3]-pmm[,4]
pt$time <- pt[,1]-pt[,2]
pt$cost <- pt[,3]-pt[,4]
plot(pt$time,pt$cost,xlim=c(-15,15),ylim=c(-6,6),pch=0,col=2)
points(pmm$time,pmm$cost,pch=2,col=3)
trend <- function(x, beta)
{
y <- beta*x
}
beta <- -0.2630
x <- seq(-15,15)
y <- trend(x,beta)
y
lines(c(x[1],tail(x,1)),c(head(y,1),tail(y,1)))
800 +600+500+600
2500*7
a <- matrix(c(15,200,50,450,135,150),2,3)
b  <- matrix(c(30,185,110,390,70,225),2,3)
c <- matrix(c(19,81,30,70,35,65),2,3)
b <- c
p1 <- b[1,1]/(b[1,1]+b[2,1])
p2 <- b[1,2]/(b[1,2]+b[2,2])
p3 <- b[1,3]/(b[1,3]+b[2,3])
p4 <- (b[1,1]+b[1,2])/(b[1,2]+b[1,1]+b[2,2]+b[2,1])
p <- (b[1,1]+b[1,2]+b[1,3])/sum(b)
l1 <-b[1,1]*log(p1)+b[2,1]*log(1-p1) + b[1,2]*log(p2)+b[2,2]*log(1-p2) + b[1,3]*log(p3)+b[2,3]*log(1-p3)
l2 <-(b[1,1]+b[1,2])*log(p4)+(b[2,1]+b[2,2])*log(1-p4) + b[1,3]*log(p3)+b[2,3]*log(1-p3)
l3 <- sum(b[1,])*log(p) + sum(b[2,])*log(1-p)
t1 <- -2*(l2-l1) #comparing unrestricted model with model2 in which medium and low income are grouped together (1 df)
t1
t2 <- -2*(l3-l2) #comparing model in which medium and low income are grouped together with completely restricted model (no income classes) (1 df)
t2
t3 <- -2*(l3-l1) #compartin unrestricted model with completely restricted model (i.e. 2 df)
t3
crit_val1df <- 3.84
crit_val2df <- 5.99
250'000/16
)
'
250000/16
15600/9
317*260
317*360
p_eva <- exp(72/100)/(exp(72/100)+exp(834/1000))
p_eva
1-2/100*18-3.75/100*2.1+0.5
p_eva <- exp(72/100)/(exp(72/100)+exp(1.06125))
p-eva
p_eva
-2/100*18-3.75/100*2.1+0.5
p_eva <- exp(72/100)/(exp(72/100)+exp(0.06125))
p_eva
m_binlog <- function(t1,c1,t2,c2,inc,univ)
{
vc <- 1-3/100*t1-6/100*c1+0.5*inc
vt <- -2/100*t2-3.75/100*c2+0.5*univ
p <- exp(vc)/(exp(vc)+exp(vt))
}
p_eva2 <- m_binlog(22,18,2,2.1,1,1)
p_eva2
eva2
p_eva
m_binlog <- function(t1,t2,c1,c2,inc,univ)
{
vc <- 1-3/100*t1-6/100*c1+0.5*inc
vt <- -2/100*t2-3.75/100*c2+0.5*univ
p <- exp(vc)/(exp(vc)+exp(vt))
return(c(vc,vt,p))
}
p_eva2 <- m_binlog(22,18,2,2.1,1,1)
p_eva2
m_binlog <- function(t1,t2,c1,c2,inc,univ)
{
vc <- 1-3/100*t1-6/100*c1+0.5*inc
vt <- -2/100*t2-3.75/100*c2+0.5*univ
p <- exp(vc)/(exp(vc)+exp(vt))
return(p)
}
p_eva2 <- m_binlog(22,18,2,2.1,1,1)
p_eva2
p_matth <- m_binlog(120,100,10,15,0,1)
p_michel <- m_binlog(10,50,3,5,1,0)
p_meri <- m_binlog(25,9,7,2.1,0,0)
p_eva
p_matth
p_meri
p_michel
help(time_zone_converter)
rm(list=ls())
eval_confusion(make_confusion(sick_times,not_sick_times, cut = mean(result$hist)),fOne=TRUE)
make_confusion(sick_times,not_sick_times, cut = mean(result$hist))
leave_one_out <- function(negative, positive, ...)
{
optimal_score = -99999999
library("gridExtra") #for saving png files in a specific order into pdf
library("ggplot2")
library('ggdendro')
# library("TSclust")
library("ggmap") #used to plot maps
library("maps")
library("scales") # for function alpha()
library("compiler")  # to speed up the computations!
library("plyr")
library("hexbin") #for hexoganal binning
library("rgeos") #for creating maps
library("png") #for reading png files
library("grid") #for arranging png files
library("data.table") #for faster creation of crosstables from data set & for faster searches of datatables; brings about a lot of speed-up! https://github.com/Rdatatable/data.table/wiki/Getting-started
library("bit64") #for loading data with fread
library("lubridate") #for handling time and date information; http://stackoverflow.com/questions/10705328/extract-hours-and-seconds-from-posixct-for-plotting-purposes-in-r
#install_github("rundel/timezone") #needs terminal commands: http://stackoverflow.com/questions/33381421/how-to-upgrade-proj4-for-rgdal
#sudo apt-get install libgdal-dev libproj-dev
library("timezone") #for getting timezones from lat/long data
library("feather") #for fast exporting and importing of data: http://blog.revolutionanalytics.com/2016/05/feather-package.html
#other possibility for fast exporting data is fwrite() using the data.table package: http://blog.h2o.ai/2016/04/fast-csv-writing-for-r/
root_path <- "~/Dropbox/UZH_Master/Masterarbeit/TwitterEpi/ExploratoryAnalysis" # defining root_path containing all relevant documents
script_path <- "~/Dropbox/UZH_Master/Masterarbeit/TwitterEpi/Non_R_Code"
setwd(root_path) # set WD back
load(file="Twitter_datatables2.RData") #use if you decided to export the whole working space
df_label <- "random"
coord_selection  <- function(datatable,coord_selec) {
selec <- datatable[datatable[,longitude >=coord_selec[1] & longitude <= coord_selec[2] & latitude >= coord_selec[3] & latitude <=coord_selec[4]],]
#selec <- datatable[which(datatable[,"longitude",]>=coord_selec[1] & datatable[,"longitude"] <= coord_selec[2] & datatable[,"latitude"] >= coord_selec[3] & datatable[,"latitude"] <= coord_selec[4]),] #old way to do it with dataframes
}
#function to make selection of datatable based on coordinate (lon_west,lon_est,lat_south,lat_north); also returns index
coord_selection2  <- function(datatable,coord_selec) #
{
selec <- datatable[datatable[,longitude >=coord_selec[1] & longitude <= coord_selec[2] & latitude >= coord_selec[3] & latitude <=coord_selec[4]],]
index <-datatable[,longitude >=coord_selec[1] & longitude <= coord_selec[2] & latitude >= coord_selec[3] & latitude <=coord_selec[4]]
return(list(selec,index))
}
coord_USA <- c(-125,-66,25,50) #select only tweets from mainland USA
df <- coord_selection(df,coord_USA)
#sick_df <- coord_selection(sick_df, coord_USA)
#healthy_df <- coord_selection(healthy_df,coord_USA)
gc()
explore_data <- function(datatable,sickness_state){ #"sickness_state" takes values "sick" or "healthy" and signifies the state that the users represented in the dataste *should* be in
all_users<-unique(datatable[,userID]) #unique returns a vector, data frame or array like x but with duplicate elements/rows removed; in this case = unique return of user_ID
num_users <- length(all_users)
sick_position <- which(datatable[,sick]==1) #gets position of tweets labelled as asick
num_sick_tweets<-sum(datatable[,sick]==1) #returns number of tweets that are labelled as "sick"
#sick_tweets<-datatable[sick_position,5] #returns entries that are labelled as sick
# NB! n sick tweets != n sick users!!!
sick_users<-unique(datatable[sick_position,userID])
num_sick_users <- length(sick_users)
#getting healthy
healthy_position <- which(datatable[,sick]==0)
#healthy_tweets <- unique(datatable[healthy_position,5]) #returns entries that are labelled as healthy
num_healthy_tweets <- sum(datatable[,sick]==0)
healthy_users <- unique(datatable[healthy_position,userID]) #getting healthy users
num_healthy_users <- length(healthy_users)
#check the total number of false labels
if (sickness_state == "sick"){ #checking whether there are any users in a "sick" datatable that have never been sick, i.e. that healthy_users that don't show up in sick_users
false_label <- healthy_users[!(healthy_users %in% sick_users)]
num_false_label <- length(false_label)
}
else if (sickness_state == "healthy"){
false_label <- sick_users
num_false_label <- num_sick_users
}
#dirty hack in order to get code running for random subsets (i.e. without sick/healthy classification) > needs to be updated for final version
else{
false_label <- sick_users
num_false_label <- num_sick_users
}
out <- list(all_users,num_users,sick_position,num_sick_tweets,sick_users,num_sick_users,healthy_position,num_healthy_tweets,healthy_users,num_healthy_users,false_label,num_false_label)
names(out) <- c("all_users","num_users", "sick_position","num_sick_tweets","sick_users","num_sick_users","healthy_position", "num_healthy_tweets", "healthy_users","num_healthy_users","false_label","num_false_label")
return(out)
}
#get preliminary info from datatables
explore_df <- explore_data(df,df_label)
str(explore_df)
explore_df <- list(explore_df$false_label) #prune list to save memory
names(explore_df) <- "false_label"
gc()
hist_coord <- function(datatable,tag,explore){
#create filenames#
filenames <- c("all_tweets","all_tweets","sicktweets","sicktweets","healthytweets","healthytweets","mislabelled","mislabelled")
filenames <- paste(filenames,tag,sep="_")
filenames <- paste(filenames,c("lon","lat"))
#define root for transformation
root <- 1/2
root_tag <- as.character(round(root,2))
#prune datatable to save memory
datatable <- datatable[,.(userID,longitude,latitude,sick)]
#create a list to store hexbins
num.plots <- 8
my.subsets <- vector(num.plots,mode="list")
# create subsets of datatable for analysis
my.subsets[[1]] <- datatable
my.subsets[[2]] <- datatable[datatable[,sick]==1,]
my.subsets[[3]] <- datatable[datatable[,sick]==0,]
my.subsets[[4]] <- datatable[which(datatable[,userID] %in% explore$false_label),]
remove(datatable) #to save memory
##create histogram of whole datatable##
pdf(file=paste0("plots/","HistogramOfCoordinates_",tag,".pdf"),onefile=T,width=20)
par(mfrow=c(1,2))
for (i in 1:(num.plots/2)){
h <- hist(my.subsets[[1]][,longitude], breaks = length(unique(my.subsets[[1]][,longitude])),plot=F) #save histdata
h$counts <- (h$counts)**root
plot(h,xlab="longitude",ylab=paste0("(frequency)^",root_tag), main=filenames[(2*i)-1])
remove(list =c("h"))
h <- hist(my.subsets[[1]][,latitude], breaks = length(unique(my.subsets[[1]][,latitude])),plot=F) #save histdata
h$counts <- (h$counts)**root
plot(h,xlab="latitude",ylab=paste0("(frequency)^",root_tag), main=filenames[(2*i)])
remove(list =c("h"))
my.subsets <- my.subsets[-1] #removing subset that was just used to save memory
gc()
}
dev.off()
}
hist_coord(df,df_label,explore_df)
hist_states <- function(datatable,tag,title_plot = "All tweets from "){
setkey(datatable,"state")
num_states<-length(unique(datatable[,state]))
states_activity<-  datatable[,.N,by=.(state)]
colnames(states_activity) <- c("state","freq")
filenames <- paste0("plots/","histogram_states_",tag,".pdf")
pdf(file=filenames,width=14)
par(mfrow=c(1,2))
hist(states_activity$freq, breaks = "FD",main= paste0(title_plot,tag,' - States activity'), xlab = 'numb. of tweets', ylab = "num. of states")
barplot(as.array(states_activity$freq),names.arg=states_activity$state,ylab="num. of tweets",xlab = "states",main=paste0(title_plot,tag,' States activity'))
dev.off()
}
hist_states(df, df_label)
load(file="Twitter_datatables.RData") #use if you decided to export the whole working space
hist_coord(sick_df, "sick_df",explore_sick)
explore_sick <- explore_data(sick_df,"sick")
str(explore_sick)
explore_sick <- list(explore_sick$false_label) #prune list to save memory
names(explore_sick) <- "false_label"
hist_coord(sick_df, "sick_df",explore_sick)
hist_states(sick_df, "sick_df")
user_activity <- function(datatable,tag){#datatable has to be in the form of a data.table; preferentially with key already set to "userID"
setkey(datatable,"userID")
user_ac <- datatable[,.N,by=.(userID)] #".N" is a shortcut for length(current_object), in this case, it outputs the nunber of occurences of each user in the column userID; .() is a shorthand for "list"
#user_ac[,N:=log10(N)]
user_ac[,N:=N-1]
#user_ac[,N:=N**(1/15)]
#Freedman-Diaconis rule to calculate optimal bin-width http://stats.stackexchange.com/questions/798/calculating-optimal-number-of-bins-in-a-histogram
bw <- 2*IQR(user_ac$N)/(length(user_ac$N)**(1/3))
brx <- pretty(range(user_ac$N), n = nclass.Sturges(user_ac$N),min.n = 1) #http://stackoverflow.com/questions/25146544/r-emulate-the-default-behavior-of-hist-with-ggplot2-for-bin-width
filenames <- paste0("plots/","user_activity_",tag,".pdf")
pdf(file=filenames,width=20)
#create histogram & density plot using raw counts
activity_plot <- ggplot(data =  user_ac, aes(x = user_ac[,N]))+
geom_histogram(aes(y=..density..), colour="black",fill="white",binwidth=1) + geom_density(alpha=.2, fill="#FF6666") +ggtitle(paste0('user activity_',tag))+
xlab('numb. of tweets') + ylab("proportion of users") + scale_x_continuous(limits=c(0,50),expand=c(0,0))  # Overlay with transparent density plot
print(activity_plot)
dev.off()
#note to me: find out how to set x-Axes to zero
}
# user_activity(sick_df,"sick_df")
# user_activity(healthy_df,"healthy_df")
user_activity(df,df_label)
help(poisson)
help(ran)
help(rand)
help(rnorm)
n <- rpois(1000)
n
n <- rpois(1000,1)
n
hist(n)
n <- rpois(1000,0.5)
n <- rpois(1000,0.5)
n
hist(n)
help(rpois)
n <- rpois(100000,0.5)
hist(n)
n
n <- rexp(10000)
n
hist(n)
help(rexp)
n <- rexp(10000,rate=0.5)
n
hist(n)
user_ac <- df[,.N,by=.(userID)]
user_ac
n
length(n)
a <- seq(1,1000)
ddf <- data.table(a,n)
ddf
dplot <- ggplot(data=ddf,aes(x=ddf[,n])) + geom_histogram()
dplot
n < 0
length(n <0)
sum(n <0)
dplot <- ggplot(data=ddf,aes(x=ddf[,n])) + geom_histogram()+ scale_x_continuous(limits=c(0,20))
dplot
help(geom_histogram)
dplot <- ggplot(data=ddf,aes(x=ddf[,n])) + geom_histogram(center = 0.5)+ scale_x_continuous(limits=c(0,20))
dplot
ggplot(data=ddf,aes(x=ddf[,n])) + geom_histogram(center = 0)+ scale_x_continuous(limits=c(0,20))
ggplot(data=ddf,aes(x=ddf[,n])) + geom_histogram(center = 1)+ scale_x_continuous(limits=c(0,20))
ggplot(data=ddf,aes(x=ddf[,n])) + geom_histogram(boundary = 0)+ scale_x_continuous(limits=c(0,20))
datatable <- df
setkey(datatable,"userID")
user_ac <- datatable[,.N,by=.(userID)] #".N" is a shortcut for length(current_object), in this case, it outputs the nunber of occurences of each user in the column userID; .() is a shorthand for "list"
#user_ac[,N:=log10(N)]
user_ac[,N:=N-1]
#user_ac[,N:=N**(1/15)]
#Freedman-Diaconis rule to calculate optimal bin-width http://stats.stackexchange.com/questions/798/calculating-optimal-number-of-bins-in-a-histogram
bw <- 2*IQR(user_ac$N)/(length(user_ac$N)**(1/3))
brx <- pretty(range(user_ac$N), n = nclass.Sturges(user_ac$N),min.n = 1) #http://stackoverflow.com/questions/25146544/r-emulate-the-default-behavior-of-hist-with-ggplot2-for-bin-width
filenames <- paste0("plots/","user_activity_",tag,".pdf")
activity_plot <- ggplot(data =  user_ac, aes(x = user_ac[,N]))+
geom_histogram(aes(y=..density..,boundary=0), colour="black",fill="white",binwidth=1) + geom_density(alpha=.2, fill="#FF6666") +ggtitle(paste0('user activity_',tag))+
xlab('numb. of tweets') + ylab("proportion of users") + scale_x_continuous(limits=c(0,50),expand=c(0,0))  # Overlay with transparent density plot
tag <- test
tag <- "test"
activity_plot <- ggplot(data =  user_ac, aes(x = user_ac[,N]))+
geom_histogram(aes(y=..density..,boundary=0), colour="black",fill="white",binwidth=1) + geom_density(alpha=.2, fill="#FF6666") +ggtitle(paste0('user activity_',tag))+
xlab('numb. of tweets') + ylab("proportion of users") + scale_x_continuous(limits=c(0,50),expand=c(0,0))  # Overlay with transparent density plot
help(geom_histogram)
activity_plot <- ggplot(data =  user_ac, aes(x = user_ac[,N]))+
geom_histogram(aes(y=..density..), colour="black",fill="white",binwidth=1,boundary=0) + geom_density(alpha=.2, fill="#FF6666") +ggtitle(paste0('user activity_',tag))+
xlab('numb. of tweets') + ylab("proportion of users") + scale_x_continuous(limits=c(0,50),expand=c(0,0))  # Overlay with transparent density plot
activity_plot
activity_plot <- ggplot(data =  user_ac, aes(x = user_ac[,N]))+
geom_histogram(aes(y=..density..), colour="black",fill="white",binwidth=bw,boundary=0) + geom_density(alpha=.2, fill="#FF6666") +ggtitle(paste0('user activity_',tag))+
xlab('numb. of tweets') + ylab("proportion of users") + scale_x_continuous(limits=c(0,50),expand=c(0,0))  # Overlay with transparent density plot
activity_plot
geom_histogram(aes(y=..density..), colour="black",fill="white",breaks=brx,boundary=0) + geom_density(alpha=.2, fill="#FF6666") +ggtitle(paste0('user activity_',tag))+
xlab('numb. of tweets') + ylab("proportion of users") + scale_x_continuous(limits=c(0,50),expand=c(0,0))  # Overlay with transparent density plot
print(activity_plot)
activity_plot <- ggplot(data =  user_ac, aes(x = user_ac[,N]))+
geom_histogram(aes(y=..density..), colour="black",fill="white",binwidth=1,boundary=0) + geom_density(alpha=.2, fill="#FF6666") +ggtitle(paste0('user activity_',tag))+
xlab('numb. of tweets') + ylab("proportion of users") + scale_x_continuous(limits=c(0,50),expand=c(0,0))  # Overlay with transparent density plot
print(activity_plot)
activity_plot <- ggplot(data =  user_ac, aes(x = user_ac[,N]))+
geom_histogram(aes(y=..density..), colour="black",fill="white",breaks=brx,boundary=0) + geom_density(alpha=.2, fill="#FF6666") +ggtitle(paste0('user activity_',tag))+
xlab('numb. of tweets') + ylab("proportion of users") + scale_x_continuous(limits=c(0,50),expand=c(0,0))  # Overlay with transparent density plot
activity_plot
help(geom_histogram)
brx
brx <- pretty(range(user_ac$N), n = nclass.Sturges(user_ac$N),min.n = 1) #http://stackoverflow.com/questions/25146544/r-emulate-the-default-behavior-of-hist-with-ggplot2-for-bin-width
brx
activity_plot <- ggplot(data =  user_ac, aes(x = user_ac[,N]))+
geom_histogram(aes(y=..density..), colour="black",fill="white",binwidth=0.5,boundary=0) + geom_density(alpha=.2, fill="#FF6666") +ggtitle(paste0('user activity_',tag))+
xlab('numb. of tweets') + ylab("proportion of users") + scale_x_continuous(limits=c(0,50),expand=c(0,0))  # Overlay with transparent density plot
activity_plot
activity_plot <- ggplot(data =  user_ac, aes(x = user_ac[,N]))+
geom_histogram(aes(y=..density..), colour="black",fill="white",binwidth=1,boundary=0) + geom_density(alpha=.2, fill="#FF6666") +ggtitle(paste0('user activity_',tag))+
xlab('numb. of tweets') + ylab("proportion of users") + scale_x_continuous(limits=c(0,50),expand=c(0,0))  # Overlay with transparent density plot
activity_plot
user_activity <- function(datatable,tag){#datatable has to be in the form of a data.table; preferentially with key already set to "userID"
user_activity <- function(datatable,tag){#datatable has to be in the form of a data.table; preferentially with key already set to "userID"
setkey(datatable,"userID")
user_ac <- datatable[,.N,by=.(userID)] #".N" is a shortcut for length(current_object), in this case, it outputs the nunber of occurences of each user in the column userID; .() is a shorthand for "list"
#user_ac[,N:=log10(N)]
user_ac[,N:=N-1]
#user_ac[,N:=N**(1/15)]
#Freedman-Diaconis rule to calculate optimal bin-width http://stats.stackexchange.com/questions/798/calculating-optimal-number-of-bins-in-a-histogram
bw <- 2*IQR(user_ac$N)/(length(user_ac$N)**(1/3))
brx <- pretty(range(user_ac$N), n = nclass.Sturges(user_ac$N),min.n = 1) #http://stackoverflow.com/questions/25146544/r-emulate-the-default-behavior-of-hist-with-ggplot2-for-bin-width
filenames <- paste0("plots/","user_activity_",tag,".pdf")
pdf(file=filenames,width=20)
#create histogram & density plot using raw counts
activity_plot <- ggplot(data =  user_ac, aes(x = user_ac[,N]))+
geom_histogram(aes(y=..density..), colour="black",fill="white",binwidth=1,boundary=0) + geom_density(alpha=.2, fill="#FF6666") +ggtitle(paste0('user activity_',tag))+
xlab('numb. of tweets') + ylab("proportion of users") + scale_x_continuous(limits=c(0,50),expand=c(0,0))  # Overlay with transparent density plot
print(activity_plot)
dev.off()
#note to me: find out how to set x-Axes to zero
}
# user_activity(sick_df,"sick_df")
# user_activity(healthy_df,"healthy_df")
user_activity(df,df_label)
)
user_activity <- function(datatable,tag){#datatable has to be in the form of a data.table; preferentially with key already set to "userID"
setkey(datatable,"userID")
user_ac <- datatable[,.N,by=.(userID)] #".N" is a shortcut for length(current_object), in this case, it outputs the nunber of occurences of each user in the column userID; .() is a shorthand for "list"
#user_ac[,N:=log10(N)]
user_ac[,N:=N-1]
#user_ac[,N:=N**(1/15)]
#Freedman-Diaconis rule to calculate optimal bin-width http://stats.stackexchange.com/questions/798/calculating-optimal-number-of-bins-in-a-histogram
bw <- 2*IQR(user_ac$N)/(length(user_ac$N)**(1/3))
brx <- pretty(range(user_ac$N), n = nclass.Sturges(user_ac$N),min.n = 1) #http://stackoverflow.com/questions/25146544/r-emulate-the-default-behavior-of-hist-with-ggplot2-for-bin-width
filenames <- paste0("plots/","user_activity_",tag,".pdf")
pdf(file=filenames,width=20)
#create histogram & density plot using raw counts
activity_plot <- ggplot(data =  user_ac, aes(x = user_ac[,N]))+
geom_histogram(aes(y=..density..), colour="black",fill="white",binwidth=1,boundary=0) + geom_density(alpha=.2, fill="#FF6666") +ggtitle(paste0('user activity_',tag))+
xlab('numb. of tweets') + ylab("proportion of users") + scale_x_continuous(limits=c(0,50),expand=c(0,0))  # Overlay with transparent density plot
print(activity_plot)
dev.off()
#note to me: find out how to set x-Axes to zero
}
# user_activity(sick_df,"sick_df")
# user_activity(healthy_df,"healthy_df")
user_activity(df,df_label)
2400+1750+1950+2450+2950
2400+1750+1950+2450+2950+3200+2900+2200
2400+1750+1950+2450+2950+3200+2900+2200+2200

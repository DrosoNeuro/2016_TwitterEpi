\chapter{Future Work}
%\section{Summary of Work}
\section{Future Directions}
\subsection{Extended Diagnostic Methods}

While our diagnostic system, described in chapter \ref{www2014}, provides a proof of concept for validated diagnosis of a disease using a combination of Twitter and medical records, there are many things that could be done to improve it. First, our system would be improved with a larger dataset. While we have shown that we can generate a good fit on a small user set, there is still the question of generalizable. Extending the dataset beyond one season of college student disease diagnoses at one university could help to address the issue of generalizable. 

This larger dataset could allow us to measure other factors besides simply the disease, such as vaccination rates or hygiene practices, which may effect the chance of someone becoming ill.\cite{viboud2004risk} Previous work \cite{mounts1999case,dinh2006risk,o2010risk}   has looked into this using surveys and other traditional data gathering methods. Due to their limited sample sizes, they tend to not be able to generate interesting insights because they can only detect ``strong'' correlations between risk factors and disease. We attempted this approach on our small dataset, but were unable to find statistical significant results. Additionally, some of the results we found seemed counterintuitive. For example, users who discuss smoking tended to be less likely to be diagnosed with influenza than ones that discussed exercise or yoga. However, this may be explained by a bias introduced in our sampling methods: users who are more health conscious may be more likely to visit a medical practitioner to get an official diagnosis. If we were to apply these risk factor detectors and influenza diagnosis systems to the general Twitter dataset--for example, the one used in chapter \ref{longitude}-- we may be able to get around these biases that would be inherent in \emph{any} medical-based survey study. Additionally, we could apply these risk factors to improve our diagnosis' accuracy. For example, a user that previously said that she was going to get an influenza vaccine is probably less likely to be later be diagnosed with influenza. 

We could automate this by employing Deep Learning\cite{LeCun:2015dt} neural networks to the dataset. An artificial neural network could be designed with L.T.M. (Long-Term-Memory) neurons\cite{el1995hierarchical,ferrari2008constrained,Pascanu:2012tw,LeCun:2015dt} to keep a persistent model of each user over a long period of time. The neural network would then employ a user's current tweets along with information stored in the L.T.M. neurons to provide a diagnosis \emph{and} update the same L.T.M. neurons. One drawback of this approach, however, is that other text processing systems\cite{sutskever2011generating,Graves:2013wt} tend to require hundreds of thousands or millions of data points before such a system can accurately learn these subtle, temporal relations.

Finally, we could extend this system to use other data sources than Twitter or to diagnose other diseases.
%
%\subsection{Targeting Super-spreaders based on Social Media Data}
%In chapter \ref{longitude}, we found a long tail distribution of the number of infections each user was believed to have caused. This provides further evidence for super spreader dynamics, where a few individuals are responsible for the majority of an outbreak. Previous work\cite{Wells:2013tp,Cattuto:2010id,Bansal:2006di,Tatem:2006jt,Salathe:2010df} has suggested that selectively targeting individuals, that are likely to become super spreaders, for vaccination is an effective strategy for reducing an outbreak's size given a limited supply of vaccines. However, predicting future super spreaders is not a trivial task. Other work has considered metrics such as network centrality\cite{Salathe:2010jf} or profession\cite{Cattuto:2010id} as predictive features. Future work could employ our measurements to preform a demographic study of super spreaders. 
%
%On a more applied side, one could implement a recommender system\cite{ricci2011introduction} which ranks Twitter users based on their likelihood of becoming super spreaders. This could then be employed by public health officials to target these potential super spreaders for encouragement of getting vaccinated or performing other preventative measures.\cite{Bond:2012ff,Weng:2012dd} Additionally, more subtle manipulations through ad placement could be considered. However, it would be difficult to actually measure the effectiveness of these methods due to the stochastic nature of peer to peer transmission\cite{balk2002correlation} and institutional safeguards regarding large scale behavioral manipulation and medical experiments. 

\subsection{Experimental Validation of Message Propagation}
While modeling retweet behavior is a well studied problem, there does not seem to be much academic research on an experimental validation of these behavioral models. One potential approach to such an experiment would be to coordinate with various Tweet creators--for example, CNN or the CDC in our health study--and see if they would be able to modify their messages in ways that the models predict would increase (or decrease) the expected number of retweets. These messages would then be ``released into the wild'' to see how many Twitter users decide to retweet the message. Clearly, many of these experiments are being done in the industrial side of research, but differing end-goals result in a lack of publication of these results. 
